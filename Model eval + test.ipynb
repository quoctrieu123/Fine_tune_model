{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-12-14T17:05:20.609642Z",
     "iopub.status.busy": "2024-12-14T17:05:20.608948Z",
     "iopub.status.idle": "2024-12-14T17:05:20.818363Z",
     "shell.execute_reply": "2024-12-14T17:05:20.817229Z",
     "shell.execute_reply.started": "2024-12-14T17:05:20.609609Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, GPT2Tokenizer\n",
    "import torchvision.transforms as T\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = (\"cuda\"if torch.cuda.is_available() else \"cpu\")\n",
    "# Đường dẫn tới model đã lưu\n",
    "save_path = \"/lastest_model.pth\"\n",
    "\n",
    "# Khởi tạo model với kiến trúc đã dùng\n",
    "image_encoder_model = \"google/vit-base-patch16-224-in21k\"\n",
    "text_decode_model = \"gpt2\"\n",
    "checkpoint = torch.load(save_path, map_location=device)\n",
    "model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(\n",
    "    image_encoder_model, text_decode_model\n",
    ")\n",
    "# Khởi tạo feature extractor và tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(text_decode_model)\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(image_encoder_model)\n",
    "# feature_extractor\n",
    "# Load trọng số đã lưu vào model\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.to(device)\n",
    "print(checkpoint[\"epoch\"])\n",
    "model.config.pad_token_id = tokenizer.pad_token_id  \n",
    "model.config.eos_token_id = tokenizer.eos_token_id \n",
    "model.config.decoder_start_token_id = tokenizer.bos_token_id  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T17:26:59.610161Z",
     "iopub.status.busy": "2024-12-14T17:26:59.609374Z",
     "iopub.status.idle": "2024-12-14T17:27:00.515465Z",
     "shell.execute_reply": "2024-12-14T17:27:00.514655Z",
     "shell.execute_reply.started": "2024-12-14T17:26:59.610129Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "from transformers import ViTFeatureExtractor, GPT2Tokenizer\n",
    "from PIL import Image\n",
    "# Ví dụ: ảnh test\n",
    "image_path = \"/kaggle/input/all-new-images/Sydney-Galaxy-homebush.jpg\"\n",
    "image = Image.open(image_path)\n",
    "transforms = T.Compose([\n",
    "    T.Resize((224,224)),\n",
    "    T.ToTensor(), # chuyển về tensor và chuẩn hóa [0,1]\n",
    "])\n",
    "\n",
    "\n",
    "image = transforms(image)  # Xử lý ảnh qua các transform\n",
    "\n",
    "\n",
    "test_inputs = feature_extractor(image, return_tensors=\"pt\",do_rescale = False)\n",
    "pixel_values = test_inputs.pixel_values\n",
    "\n",
    "\n",
    "attention_mask = (pixel_values != tokenizer.eos_token_id).long()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(pixel_values= pixel_values.to(device),attention_mask=attention_mask.to(device), max_length=20, num_beams=8, early_stopping=True)\n",
    "    caption = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.imshow(transforms(Image.open(image_path)).permute(1,2,0))\n",
    "plt.title(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T17:08:32.368754Z",
     "iopub.status.busy": "2024-12-14T17:08:32.368341Z",
     "iopub.status.idle": "2024-12-14T17:19:23.518498Z",
     "shell.execute_reply": "2024-12-14T17:19:23.517679Z",
     "shell.execute_reply.started": "2024-12-14T17:08:32.368703Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'black', 'dog', 'is', 'running', 'after', 'a', 'brown', 'dog', 'on', 'the', 'beach', '.']\n",
      "[['On', 'a', 'beach', ',', 'black', 'and', 'brown', 'dog', 'runs', ',', 'brown', 'dog', 'jumps', '.']]\n",
      "Nltk metrics\n",
      "BLEU-1: 0.5175966284859593\n",
      "BLEU-2: 0.3757594101171124\n",
      "BLEU-3: 0.29695747328856376\n",
      "BLEU-4: 0.238930920107841\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from torch.utils.data import Subset\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# Link chứa dataset\n",
    "caption_file = \"/kaggle/input/flickr8k/captions.txt\"  \n",
    "root_dir = \"/kaggle/input/flickr8k/Images\"  \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class FlickrDataset(Dataset):\n",
    "    def __init__(self, root_dir, captions_file, tokenizer, transform=None, freq_threshold=5):\n",
    "        self.root_dir = root_dir\n",
    "        self.df = pd.read_csv(captions_file)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get image and caption column from the dataframe\n",
    "        self.imgs = self.df[\"image\"]\n",
    "        self.captions = self.df[\"caption\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        caption = self.captions[idx] # lấy caption dựa trên index\n",
    "        img_name = self.imgs[idx] # lấy tên ảnh dựa trên index \n",
    "\n",
    "        # Tạo đường dẫn đến tệp ảnh dựa vào tên ảnh đã có và đổi về dạng RGB\n",
    "        img_location = os.path.join(self.root_dir, img_name)\n",
    "        img = Image.open(img_location).convert(\"RGB\")\n",
    "        if not isinstance(caption, str):\n",
    "            caption = str(caption)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)    \n",
    "    \n",
    "        return img, caption\n",
    "\n",
    "\n",
    "transforms = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "dataset = FlickrDataset(root_dir=root_dir, captions_file=caption_file, tokenizer=tokenizer, transform=transforms)\n",
    "random_indices = random.sample(range(len(dataset)), 2000)\n",
    "subset_dataset = Subset(dataset, random_indices)\n",
    "\n",
    "dataloader = DataLoader(subset_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "gc = [] \n",
    "test = [] \n",
    "    \n",
    "for i in range(len(dataloader)):\n",
    "    img, actual_caption = subset_dataset[i] \n",
    "\n",
    "    with torch.no_grad():\n",
    "           \n",
    "        test_inputs = feature_extractor(img, return_tensors=\"pt\", do_rescale=False)\n",
    "        pixel_values = test_inputs.pixel_values\n",
    "\n",
    "        attention_mask = (pixel_values != tokenizer.eos_token_id).long()\n",
    "        outputs = model.generate(pixel_values=pixel_values.to(device),\n",
    "                                    attention_mask=attention_mask.to(device),\n",
    "                                    max_length=20, num_beams=8, early_stopping=True,pad_token_id = tokenizer.eos_token_id)\n",
    "            \n",
    "        caption = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        #print(caption)\n",
    "    \n",
    "        test.append(caption.split()) \n",
    "        gc.append([actual_caption.split()]) \n",
    "#print(test[0])\n",
    "#print(gc[0])\n",
    "\n",
    "# Tính ma trận Bleu\n",
    "print(\"Nltk metrics\")\n",
    "BLEU4 = nltk.translate.bleu_score.corpus_bleu(gc, test, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "BLEU1 = nltk.translate.bleu_score.corpus_bleu(gc, test, weights=(1.0, 0, 0, 0))\n",
    "BLEU2 = nltk.translate.bleu_score.corpus_bleu(gc, test, weights=(0.5, 0.5, 0, 0))\n",
    "BLEU3 = nltk.translate.bleu_score.corpus_bleu(gc, test, weights=(0.33, 0.33, 0.33, 0))\n",
    "    \n",
    "print(f\"BLEU-1: {BLEU1}\")\n",
    "print(f\"BLEU-2: {BLEU2}\")\n",
    "print(f\"BLEU-3: {BLEU3}\")\n",
    "print(f\"BLEU-4: {BLEU4}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 623289,
     "sourceId": 1111676,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6297786,
     "sourceId": 10192730,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6303599,
     "sourceId": 10200859,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 212970127,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
