{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T19:17:45.643437Z",
     "iopub.status.busy": "2024-12-13T19:17:45.642882Z",
     "iopub.status.idle": "2024-12-13T19:17:45.649545Z",
     "shell.execute_reply": "2024-12-13T19:17:45.648594Z",
     "shell.execute_reply.started": "2024-12-13T19:17:45.643376Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader,Dataset,random_split\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from transformers import ViTImageProcessor, AutoTokenizer, VisionEncoderDecoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T19:17:45.651501Z",
     "iopub.status.busy": "2024-12-13T19:17:45.651259Z",
     "iopub.status.idle": "2024-12-13T19:17:46.987981Z",
     "shell.execute_reply": "2024-12-13T19:17:46.986633Z",
     "shell.execute_reply.started": "2024-12-13T19:17:45.651478Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_location =  \"../input/flickr30k\"\n",
    "!ls $data_location\n",
    "\n",
    "# in ra độ dài của file txt )gồm caption và hình ảnh tương ứng\n",
    "\n",
    "caption_file = data_location + '/captions.txt'\n",
    "df = pd.read_csv(caption_file)\n",
    "print(\"There are {} image to captions\".format(len(df)))\n",
    "df.head(7)\n",
    "df= df.astype(str)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T19:17:46.989718Z",
     "iopub.status.busy": "2024-12-13T19:17:46.989417Z",
     "iopub.status.idle": "2024-12-13T19:17:47.260281Z",
     "shell.execute_reply": "2024-12-13T19:17:47.259279Z",
     "shell.execute_reply.started": "2024-12-13T19:17:46.989686Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "# vẽ ra ảnh cùng 5 caption tương ứng của ảnh đó\n",
    "\n",
    "data_idx = 0\n",
    "\n",
    "image_path = data_location+\"/Images/\"+df.iloc[data_idx,0]\n",
    "img=mpimg.imread(image_path)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "image = Image.open(image_path)\n",
    "\n",
    "for i in range(data_idx,data_idx+5):\n",
    "    print(\"Caption:\",df.iloc[i,1])\n",
    "print(image.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T19:17:47.263097Z",
     "iopub.status.busy": "2024-12-13T19:17:47.262756Z",
     "iopub.status.idle": "2024-12-13T19:17:52.630475Z",
     "shell.execute_reply": "2024-12-13T19:17:52.629538Z",
     "shell.execute_reply.started": "2024-12-13T19:17:47.263061Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import VisionEncoderDecoderModel, AutoTokenizer, AutoFeatureExtractor\n",
    "image_encoder_model = \"google/vit-base-patch16-224-in21k\"\n",
    "text_decode_model = \"gpt2\"\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(\n",
    "    image_encoder_model, text_decode_model) # khởi tạo 1 model với cấu trúc gồm image encoder (vit-base-patch) và text decoder (gpt2)\n",
    "\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(image_encoder_model)\n",
    "# feature extractor bản chất chỉ có tác dụng resize ảnh về 224x224 và rescale pixel values và [0,1]\n",
    "# giúp để sẵn sàng đưa vào image encoder của model\n",
    "tokenizer = AutoTokenizer.from_pretrained(text_decode_model)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "#test the tokenizer\n",
    "''' \n",
    "print(tokenizer.tokenize(\"i love vietnam\"))\n",
    "print(tokenizer.special_tokens_map)\n",
    "print(tokenizer.convert_tokens_to_ids(tokenizer.special_tokens_map))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T19:17:52.632518Z",
     "iopub.status.busy": "2024-12-13T19:17:52.631766Z",
     "iopub.status.idle": "2024-12-13T19:17:52.639796Z",
     "shell.execute_reply": "2024-12-13T19:17:52.638892Z",
     "shell.execute_reply.started": "2024-12-13T19:17:52.632458Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FlickrDataset(Dataset): #khởi tạo dataset để đưa vào dataloader\n",
    "\n",
    "    def __init__(self,root_dir,captions_file,tokenizer,transform=None,freq_threshold=5):\n",
    "        self.root_dir = root_dir\n",
    "        self.df = pd.read_csv(caption_file)\n",
    "        self.transform = transform\n",
    "        \n",
    "       \n",
    "        self.imgs = self.df[\"image\"]\n",
    "        self.captions = self.df[\"caption\"]\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        caption = self.captions[idx] # lấy caption dựa trên index\n",
    "        img_name = self.imgs[idx] # lấy tên ảnh dựa trên index \n",
    "\n",
    "        # tạo đường dẫn đến tệp ảnh dựa vào tên ảnh đã có và đổi về dạng RGB\n",
    "        img_location = os.path.join(self.root_dir,img_name)\n",
    "        img = Image.open(img_location).convert(\"RGB\")\n",
    "        if not isinstance(caption, str):\n",
    "            caption = str(caption)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)    \n",
    "        labels = tokenizer(caption, \n",
    "                      padding=\"max_length\", \n",
    "                      max_length= 20,truncation= True).input_ids\n",
    "        return img, torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T19:17:52.641104Z",
     "iopub.status.busy": "2024-12-13T19:17:52.640824Z",
     "iopub.status.idle": "2024-12-13T19:17:52.655584Z",
     "shell.execute_reply": "2024-12-13T19:17:52.654762Z",
     "shell.execute_reply.started": "2024-12-13T19:17:52.64108Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transforms = T.Compose([\n",
    "    T.Resize((224,224)),\n",
    "    T.ToTensor(), # chuyển về tensor và chuẩn hóa [0,1], thay tác dụng của feature extractor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T19:17:52.656824Z",
     "iopub.status.busy": "2024-12-13T19:17:52.656587Z",
     "iopub.status.idle": "2024-12-13T19:17:52.666643Z",
     "shell.execute_reply": "2024-12-13T19:17:52.665893Z",
     "shell.execute_reply.started": "2024-12-13T19:17:52.656801Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def show_image(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T19:17:52.667788Z",
     "iopub.status.busy": "2024-12-13T19:17:52.667536Z",
     "iopub.status.idle": "2024-12-13T19:17:52.875087Z",
     "shell.execute_reply": "2024-12-13T19:17:52.874059Z",
     "shell.execute_reply.started": "2024-12-13T19:17:52.667756Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_location =  \"../input/flickr30k\"\n",
    "valdata_location = \"../input/flickr8k\"\n",
    "dataset =  FlickrDataset(\n",
    "    root_dir = data_location+\"/Images\",\n",
    "    captions_file = data_location+\"/captions.txt\",\n",
    "    transform=transforms, tokenizer = tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T19:17:52.876664Z",
     "iopub.status.busy": "2024-12-13T19:17:52.876302Z",
     "iopub.status.idle": "2024-12-13T19:17:52.88158Z",
     "shell.execute_reply": "2024-12-13T19:17:52.880621Z",
     "shell.execute_reply.started": "2024-12-13T19:17:52.876627Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_size = int(0.9*len(dataset))\n",
    "valid_size = len(dataset) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T19:17:52.885835Z",
     "iopub.status.busy": "2024-12-13T19:17:52.885393Z",
     "iopub.status.idle": "2024-12-13T19:17:52.913306Z",
     "shell.execute_reply": "2024-12-13T19:17:52.912464Z",
     "shell.execute_reply.started": "2024-12-13T19:17:52.8858Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data,valid_data = random_split(dataset,[train_size,valid_size]) \n",
    "# chia train và valid thoe tỷ lệ 9:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T19:17:52.914572Z",
     "iopub.status.busy": "2024-12-13T19:17:52.914328Z",
     "iopub.status.idle": "2024-12-13T19:17:52.91907Z",
     "shell.execute_reply": "2024-12-13T19:17:52.91829Z",
     "shell.execute_reply.started": "2024-12-13T19:17:52.914548Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(len(dataset))\n",
    "print(len(train_data))\n",
    "print(len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T19:17:52.920343Z",
     "iopub.status.busy": "2024-12-13T19:17:52.920104Z",
     "iopub.status.idle": "2024-12-13T19:17:53.31922Z",
     "shell.execute_reply": "2024-12-13T19:17:53.318291Z",
     "shell.execute_reply.started": "2024-12-13T19:17:52.92032Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token # chuyển pad_token thành eos_token\n",
    "img, caps= dataset[5]\n",
    "show_image(img,\"Image\")\n",
    "print(\"Token:\",caps)\n",
    "print(img.shape)\n",
    "print(caps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T19:17:53.320345Z",
     "iopub.status.busy": "2024-12-13T19:17:53.320106Z",
     "iopub.status.idle": "2024-12-13T19:17:53.324295Z",
     "shell.execute_reply": "2024-12-13T19:17:53.323477Z",
     "shell.execute_reply.started": "2024-12-13T19:17:53.320322Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T19:17:53.325576Z",
     "iopub.status.busy": "2024-12-13T19:17:53.325289Z",
     "iopub.status.idle": "2024-12-13T19:17:53.334988Z",
     "shell.execute_reply": "2024-12-13T19:17:53.334181Z",
     "shell.execute_reply.started": "2024-12-13T19:17:53.325549Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKER,\n",
    "    shuffle=True,\n",
    ")\n",
    "valid_loader = DataLoader(dataset=valid_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKER,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T19:17:53.335976Z",
     "iopub.status.busy": "2024-12-13T19:17:53.335729Z",
     "iopub.status.idle": "2024-12-13T19:17:54.229647Z",
     "shell.execute_reply": "2024-12-13T19:17:54.228807Z",
     "shell.execute_reply.started": "2024-12-13T19:17:53.335952Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(len(train_loader))\n",
    "for images,inputs_ids in train_loader:\n",
    "    print(images.shape)\n",
    "    print(inputs_ids.shape)\n",
    "    image =images[0]\n",
    "    inputs_id = inputs_ids[0]\n",
    "    plt.imshow(image.permute(1,2,0))\n",
    "    print(\"Input_id: \",inputs_id)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T19:17:54.231496Z",
     "iopub.status.busy": "2024-12-13T19:17:54.230878Z",
     "iopub.status.idle": "2024-12-13T19:17:55.034198Z",
     "shell.execute_reply": "2024-12-13T19:17:55.033283Z",
     "shell.execute_reply.started": "2024-12-13T19:17:54.231455Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(len(valid_loader))\n",
    "for images,inputs_ids in valid_loader:\n",
    "    print(images.shape)\n",
    "    print(inputs_ids.shape)\n",
    "    image =images[0]\n",
    "    inputs_id = inputs_ids[0]\n",
    "    plt.imshow(image.permute(1,2,0))\n",
    "    print(\"Input_id: \",inputs_id)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T19:17:55.035723Z",
     "iopub.status.busy": "2024-12-13T19:17:55.035364Z",
     "iopub.status.idle": "2024-12-13T19:17:55.039905Z",
     "shell.execute_reply": "2024-12-13T19:17:55.039092Z",
     "shell.execute_reply.started": "2024-12-13T19:17:55.035685Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T19:17:55.041481Z",
     "iopub.status.busy": "2024-12-13T19:17:55.041118Z",
     "iopub.status.idle": "2024-12-13T19:17:55.053869Z",
     "shell.execute_reply": "2024-12-13T19:17:55.052913Z",
     "shell.execute_reply.started": "2024-12-13T19:17:55.041456Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "num_epoch = 10\n",
    "optimizer = AdamW(model.parameters(),lr = lr)\n",
    "loss = CrossEntropyLoss()\n",
    "best_valid_loss = 10000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T19:17:55.05512Z",
     "iopub.status.busy": "2024-12-13T19:17:55.054869Z",
     "iopub.status.idle": "2024-12-13T19:17:55.075013Z",
     "shell.execute_reply": "2024-12-13T19:17:55.074209Z",
     "shell.execute_reply.started": "2024-12-13T19:17:55.055097Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T19:17:55.076269Z",
     "iopub.status.busy": "2024-12-13T19:17:55.07601Z",
     "iopub.status.idle": "2024-12-13T19:17:55.081418Z",
     "shell.execute_reply": "2024-12-13T19:17:55.08057Z",
     "shell.execute_reply.started": "2024-12-13T19:17:55.076246Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.config.eos_token_id = tokenizer.eos_token_id # chuyển kết thúc câu là eos token\n",
    "model.config.decoder_start_token_id = tokenizer.bos_token_id #chuyển bắt đầu câu là token bos\n",
    "model.config.pad_token_id = tokenizer.pad_token_id #chuyển token_pad là pad_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token # tokenizer cũng pad bằng eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T19:17:55.082603Z",
     "iopub.status.busy": "2024-12-13T19:17:55.082376Z",
     "iopub.status.idle": "2024-12-13T19:18:09.011971Z",
     "shell.execute_reply": "2024-12-13T19:18:09.011043Z",
     "shell.execute_reply.started": "2024-12-13T19:17:55.08258Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install wandb\n",
    "import wandb\n",
    "!wandb login \"1a1e9d904fb11812f635b8c3f9a93ae09da4cd04\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T19:18:09.014284Z",
     "iopub.status.busy": "2024-12-13T19:18:09.013829Z",
     "iopub.status.idle": "2024-12-13T19:18:13.712208Z",
     "shell.execute_reply": "2024-12-13T19:18:13.711301Z",
     "shell.execute_reply.started": "2024-12-13T19:18:09.01422Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wandb.init(project = \"My final train model from 1412\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T19:18:13.713942Z",
     "iopub.status.busy": "2024-12-13T19:18:13.713568Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "for epoch in range(1, num_epoch + 1, 1):\n",
    "    model.train() \n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    total_loss = 0\n",
    "\n",
    "    progress_bar = tqdm(enumerate(train_loader, 1), total=len(train_loader), desc=f\"Epoch {epoch}\")\n",
    "\n",
    "    for batch, (img, inputs_ids) in progress_bar:\n",
    "        with torch.no_grad():\n",
    "            img_encoded = feature_extractor(img, do_rescale=False)\n",
    "        img_encoded = torch.tensor(np.array(img_encoded[\"pixel_values\"])).to(device)\n",
    "        inputs_ids = inputs_ids.to(device)\n",
    "\n",
    "\n",
    "        output = model(labels=inputs_ids, pixel_values=img_encoded)\n",
    "        loss = output.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "       \n",
    "        progress_bar.set_postfix({\"Batch Loss\": loss.item()})\n",
    "        if batch % 200 == 0:\n",
    "            print(f\"Batch {batch} of epoch{epoch} completed\")\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    wandb.log({\"avg_train_loss\": avg_loss, \"epoch\": epoch})\n",
    "    print(f\"Epoch {epoch}/{num_epoch}, Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    model.eval() \n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():  \n",
    "        for batch, (img, inputs_ids) in tqdm(enumerate(valid_loader, 1), total=len(valid_loader), desc=\"Validation\"):\n",
    "            img_encoded = feature_extractor(img, do_rescale=False)\n",
    "            img_encoded = torch.tensor(np.array(img_encoded[\"pixel_values\"])).to(device)\n",
    "            inputs_ids = inputs_ids.to(device)\n",
    "\n",
    "\n",
    "            output = model(labels=inputs_ids, pixel_values=img_encoded)\n",
    "            val_loss = output.loss\n",
    "            total_val_loss += val_loss.item()\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(valid_loader)\n",
    "    wandb.log({\"avg_valid_loss\": avg_val_loss, \"epoch\": epoch})\n",
    "    print(f\"Epoch {epoch}/{num_epoch}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "    if avg_valid_loss < best_valid_loss:\n",
    "        save_path = f\"lastest_model.pth\"\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_val_loss,\n",
    "        }, save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 623289,
     "sourceId": 1111676,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 623329,
     "sourceId": 1111749,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6282126,
     "sourceId": 10171655,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6293612,
     "sourceId": 10187259,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 190821,
     "modelInstanceId": 168476,
     "sourceId": 197540,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
